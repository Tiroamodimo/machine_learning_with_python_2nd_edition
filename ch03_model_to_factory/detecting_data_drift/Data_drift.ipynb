{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Detecting Data Drift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we must import the TabularDrift detector from the alibi-detect package, as well as the relevant packages for loading and splitting the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import alibi\n",
    "from alibi_detect.cd import TabularDrift"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T13:56:45.244514196Z",
     "start_time": "2023-08-22T13:56:43.936798684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we must get and split the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "wine_data = load_wine()\n",
    "feature_names = wine_data.feature_names\n",
    "X, y = wine_data.data, wine_data.target\n",
    "X_ref, X_test, y_ref, y_test = train_test_split(X, y,\n",
    "                                                test_size=0.50,\n",
    "                                                random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T13:57:03.568268987Z",
     "start_time": "2023-08-22T13:57:03.563544309Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we must initialize our drift detector using the reference data and by providing the p-value we want to be used by the statistical significance tests. If you want to make your drift detector trigger when smaller differences occur in the data distribution, you must select a larger p_val:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n        1.065e+03],\n       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n        1.050e+03],\n       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n        1.185e+03],\n       ...,\n       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n        8.350e+02],\n       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n        8.400e+02],\n       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n        5.600e+02]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T15:05:34.550050577Z",
     "start_time": "2023-08-22T15:05:34.543308432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "TabularDrift?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T13:57:39.743078630Z",
     "start_time": "2023-08-22T13:57:39.686218727Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/letlhogile/Documents/dev_environments/jupyter_nb_general/lib/python3.11/site-packages/alibi_detect/cd/tabular.py:113: UserWarning: No `categories_per_feature` dict provided so all features are assumed to be numerical. `KSDrift` will be applied to all features.\n",
      "  warnings.warn('No `categories_per_feature` dict provided so all features are assumed to be numerical. '\n"
     ]
    }
   ],
   "source": [
    "cd = TabularDrift(x_ref=X_ref, p_val=.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T13:57:53.178306904Z",
     "start_time": "2023-08-22T13:57:53.174781212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift: No\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_test)\n",
    "labels = ['No', 'Yes']\n",
    "print('Drift: {}'.format(labels[preds['data']['is_drift']]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T13:58:44.709112664Z",
     "start_time": "2023-08-22T13:58:44.665539302Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This returns 'Drift: No'.\n",
    "\n",
    "So, we have not detected drift here, as expected (see the following Important note for more on this)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although there was no drift in this case, we can easily simulate a scenario where the chemical apparatus being used for measuring the chemical properties experienced a calibration error, and all the values are recorded as 10% higher than their true values.\n",
    "\n",
    "In this case, if we run drift detection again on the same reference dataset, we will get the following output:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift: Yes\n"
     ]
    }
   ],
   "source": [
    "X_test_cal_error = 1.1*X_test\n",
    "preds = cd.predict(X_test_cal_error)\n",
    "labels = ['No', 'Yes']\n",
    "print('Drift: {}'.format(labels[preds['data']['is_drift']]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T14:00:55.356967898Z",
     "start_time": "2023-08-22T14:00:55.317916357Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This returns 'Drift: Yes'.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This returns 'Drift: Yes', showing that the drift has been successfully detected.\n",
    "\n",
    "IMPORTANT NOTE\n",
    "\n",
    "This example is very artificial but is useful for illustrating the point. In a standard dataset like this, there won't be data drift between 50% of the randomly sampled data and the other 50% of the data. This is why we have to artificially shift some of the points to show that the detector does indeed work. In real-world scenarios, data drift can occur naturally due to everything from updates to sensors being used for measurements; to changes in consumer behavior; all the way through to changes in database software or schemas. So, be on guard as many drift cases won't be as easy to spot as in this case!\n",
    "\n",
    "This example shows how, with a few simple lines of Python, we can detect a change in our dataset, which means our ML model may start to degrade in performance if we do not retrain to take the new properties of the data into account. We can also use similar techniques to track when the performance metrics of our model, for example accuracy or mean squared error, are drifting as well. In this case we have to make sure we periodically calculate performance on new test or validation datasets.\n",
    "\n",
    "The first drift detection example was very simple, and showed us how to detect a basic case of one-off of data drift, specifically feature drift. We will now show an example of detecting label drift, which is basically the same but now we simply use the labels as the reference and comparison data set. We will ignore the first few steps as they are identical, and resume from the point where we have reference and test datasets available."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As in the example for the drift in the features, we can configure the tabular drift detector, but now we will use the initial label as our baseline dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cd = TabularDrift(x_ref=y_ref, p_val=.05, categories_per_feature={})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T15:07:10.725429494Z",
     "start_time": "2023-08-22T15:07:10.684029163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift: No\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(y_test)\n",
    "labels = ['No', 'Yes']\n",
    "print('Drift: {}'.format(labels[preds['data']['is_drift']]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T15:07:30.829169439Z",
     "start_time": "2023-08-22T15:07:30.789938339Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This returns 'Drift: No'.\n",
    "\n",
    "So, we have not detected drift here, as expected. Note that this method can also be used as a good sanity check that training and test data labels follow similar distributions and our sampling of test data is representative.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now move onto a far more complex scenario, which is detecting concept drift."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detecting concept drift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concept drift was described in the ‘Retraining Required’ section, and there it was emphasized that this type of drift is really all about a change in the relationships between the variables in our model. This means by definition that it is far more likely that cases of this type will be complex and potentially quite hard to diagnose.\n",
    "\n",
    "The most common way that you can catch concept drift is by monitoring the performance of your model through time. For example, if we are working with the wine classification problem again, we can look at metrics that tell us the models classification performance, plot these through time and then build logic around the trends and outliers that we might see in these values.\n",
    "\n",
    "The alibi_detect package, which we have already been using, has several useful methods for online drift detection that can be used to find concept drift as it happens and impacts model performance. Online here refers to the fact that the drift detection takes place at the level of a single data point, so that this can happen even if data comes in completely sequentially in production. Several of these assume that either PyTorch or TensorFlow are available as backends since the methods use Untrained AutoEncoders (UAEs) as out of the box pre-processing methods.\n",
    "\n",
    "As an example, let us walk through an example of creating and using one of these online detectors, the Online Maximum Mean Discrepancy method. The following example assumes that in addition to the reference data set, x_ref, we have also defined variables for the expected run time, ert, and the window size, window_size. The expected run time is a variable that states the average number of data points the detector should run before it raises false positive detection. The idea here is that you want the expected run time to be larger but as it gets larger then the detector becomes more insensitive to actual drift, so a balance must be struck. The window_size is the size of the sliding window of data used in order to calculate the appropriate drift test statistic. A smaller window_size means you are tuning the detector to find sharp changes in the data or performance in a small ‘time’ frame whereas longer window sizes will mean you are tuning to look for more subtle drift effects over longer periods of ‘time’."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from alibi_detect.cd import MMDDriftOnline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:07:52.216883550Z",
     "start_time": "2023-08-22T18:07:52.173584572Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then initialise the drift detector with some variable settings as discussed in the previous paragraph. We also include the number of bootstraped simulations we want to apply in order for the method to calculate some thresholds for detecting the drift. Depending on your hardware settings for the deep learning library used and the size of the data, this may take some time.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`Framework.PYTORCH` not installed. Cannot initialize and run MMDDriftOnline with pytorch backend. The necessary missing dependencies can be installed using `pip install alibi-detect[torch]`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m ert \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m      2\u001B[0m window_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m----> 3\u001B[0m cd \u001B[38;5;241m=\u001B[39m \u001B[43mMMDDriftOnline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mert\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpytorch\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_bootstraps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2500\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/dev_environments/jupyter_nb_general/lib/python3.11/site-packages/alibi_detect/cd/mmd_online.py:83\u001B[0m, in \u001B[0;36mMMDDriftOnline.__init__\u001B[0;34m(self, x_ref, ert, window_size, backend, preprocess_fn, x_ref_preprocessed, kernel, sigma, n_bootstraps, device, verbose, input_shape, data_type)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_config(\u001B[38;5;28mlocals\u001B[39m())\n\u001B[1;32m     78\u001B[0m backend \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mlower()\n\u001B[1;32m     79\u001B[0m \u001B[43mBackendValidator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mFramework\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTENSORFLOW\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mFramework\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTENSORFLOW\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mFramework\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPYTORCH\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mFramework\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPYTORCH\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconstruct_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\n\u001B[0;32m---> 83\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverify_backend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlocals\u001B[39m()\n\u001B[1;32m     86\u001B[0m args \u001B[38;5;241m=\u001B[39m [kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_ref\u001B[39m\u001B[38;5;124m'\u001B[39m], kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mert\u001B[39m\u001B[38;5;124m'\u001B[39m], kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwindow_size\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[0;32m~/Documents/dev_environments/jupyter_nb_general/lib/python3.11/site-packages/alibi_detect/utils/frameworks.py:103\u001B[0m, in \u001B[0;36mBackendValidator.verify_backend\u001B[0;34m(self, backend)\u001B[0m\n\u001B[1;32m    100\u001B[0m         missing_deps\u001B[38;5;241m.\u001B[39mappend(dependency)\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing_deps:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_import_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmissing_deps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/dev_environments/jupyter_nb_general/lib/python3.11/site-packages/alibi_detect/utils/frameworks.py:116\u001B[0m, in \u001B[0;36mBackendValidator._raise_import_error\u001B[0;34m(self, missing_deps, backend)\u001B[0m\n\u001B[1;32m    111\u001B[0m error_msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_deps_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not installed. Cannot initialize and run \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstruct_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    112\u001B[0m              \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwith \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m backend.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    113\u001B[0m pip_msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m optional_dependencies \u001B[38;5;28;01melse\u001B[39;00m \\\n\u001B[1;32m    114\u001B[0m     (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe necessary missing dependencies can be installed using \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    115\u001B[0m      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`pip install alibi-detect[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(optional_dependencies)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]`.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 116\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_msg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpip_msg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: `Framework.PYTORCH` not installed. Cannot initialize and run MMDDriftOnline with pytorch backend. The necessary missing dependencies can be installed using `pip install alibi-detect[torch]`."
     ]
    }
   ],
   "source": [
    "ert = 50\n",
    "window_size = 10\n",
    "cd = MMDDriftOnline(X_ref, ert, window_size, backend='pytorch', n_bootstraps=2500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:07:54.422598205Z",
     "start_time": "2023-08-22T18:07:54.397803942Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then simulate the drift detection in a production setting by taking the test data from the Wine dataset and feeding it in one feature vector at a time. If the feature vector for any given instance of data is given by x, we can then call the predict method of the drift detector and retrieve the ‘is_drift’ value from the returned metadata like so:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cd.predict(X)['data']['is_drift']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
